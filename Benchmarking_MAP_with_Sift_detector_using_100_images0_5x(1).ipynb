{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Benchmarking_MAP_with_Sift_detector_using_100_images0_5x.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa8bfJcWCWFb"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import scipy.io\n",
        "import os\n",
        "from numpy.linalg import norm\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy.linalg import det\n",
        "from numpy.linalg import inv\n",
        "from scipy.linalg import rq\n",
        "from numpy.linalg import svd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import sys\n",
        "from scipy import ndimage, spatial\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from skimage import io, transform,data\n",
        "from torchvision import transforms, utils\n",
        "import numpy as np\n",
        "import math\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import sklearn.svm\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import random\n",
        "from google.colab import drive\n",
        "from sklearn.metrics.cluster import completeness_score\n",
        "from sklearn.cluster import KMeans\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from functools import partial\n",
        "from torchsummary import summary\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import h5py as h5\n",
        "\n",
        "#cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "#accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "#print(\"Accelerator type = \",accelerator)\n",
        "#print(\"Pytorch verision: \", torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL9rcKHAChcb",
        "outputId": "b03f5011-13f3-484a-d5db-717c2630f619"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdSkrM1pGGNf"
      },
      "source": [
        "#!pip install ipython-autotime\n",
        "\n",
        "#%load_ext autotime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VFwhM5HChUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8c8ae9-1edd-4be2-a463-8515a97fdec2"
      },
      "source": [
        "!pip install opencv-python==3.4.2.17\n",
        "!pip install opencv-contrib-python==3.4.2.17"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python==3.4.2.17 in /usr/local/lib/python3.7/dist-packages (3.4.2.17)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==3.4.2.17) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python==3.4.2.17 in /usr/local/lib/python3.7/dist-packages (3.4.2.17)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==3.4.2.17) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl3jpVdOChL1"
      },
      "source": [
        "class Image:\n",
        "    def __init__(self, img, position):\n",
        "        \n",
        "        self.img = img\n",
        "        self.position = position\n",
        "\n",
        "inlier_matchset = []\n",
        "def features_matching(a,keypointlength,threshold):\n",
        "  #threshold=0.2\n",
        "  bestmatch=np.empty((keypointlength),dtype= np.int16)\n",
        "  img1index=np.empty((keypointlength),dtype=np.int16)\n",
        "  distance=np.empty((keypointlength))\n",
        "  index=0\n",
        "  for j in range(0,keypointlength):\n",
        "    #For a descriptor fa in Ia, take the two closest descriptors fb1 and fb2 in Ib\n",
        "    x=a[j]\n",
        "    listx=x.tolist()\n",
        "    x.sort()\n",
        "    minval1=x[0]                                # min \n",
        "    minval2=x[1]                                # 2nd min\n",
        "    itemindex1 = listx.index(minval1)           #index of min val    \n",
        "    itemindex2 = listx.index(minval2)           #index of second min value \n",
        "    ratio=minval1/minval2                       #Ratio Test\n",
        "    \n",
        "    if ratio<threshold: \n",
        "      #Low distance ratio: fb1 can be a good match\n",
        "      bestmatch[index]=itemindex1\n",
        "      distance[index]=minval1\n",
        "      img1index[index]=j\n",
        "      index=index+1\n",
        "  return  [cv2.DMatch(img1index[i],bestmatch[i].astype(int),distance[i]) for i in range(0,index)]\n",
        "          \n",
        "   \n",
        "  \n",
        "def compute_Homography(im1_pts,im2_pts):\n",
        "  \"\"\"\n",
        "  im1_pts and im2_pts are 2Ã—n matrices with\n",
        "  4 point correspondences from the two images\n",
        "  \"\"\"\n",
        "  num_matches=len(im1_pts)\n",
        "  num_rows = 2 * num_matches\n",
        "  num_cols = 9\n",
        "  A_matrix_shape = (num_rows,num_cols)\n",
        "  A = np.zeros(A_matrix_shape)\n",
        "  a_index = 0\n",
        "  for i in range(0,num_matches):\n",
        "    (a_x, a_y) = im1_pts[i]\n",
        "    (b_x, b_y) = im2_pts[i]\n",
        "    row1 = [a_x, a_y, 1, 0, 0, 0, -b_x*a_x, -b_x*a_y, -b_x] # First row \n",
        "    row2 = [0, 0, 0, a_x, a_y, 1, -b_y*a_x, -b_y*a_y, -b_y] # Second row \n",
        "\n",
        "    # place the rows in the matrix\n",
        "    A[a_index] = row1\n",
        "    A[a_index+1] = row2\n",
        "\n",
        "    a_index += 2\n",
        "    \n",
        "  U, s, Vt = np.linalg.svd(A)\n",
        "\n",
        "  #s is a 1-D array of singular values sorted in descending order\n",
        "  #U, Vt are unitary matrices\n",
        "  #Rows of Vt are the eigenvectors of A^TA.\n",
        "  #Columns of U are the eigenvectors of AA^T.\n",
        "  H = np.eye(3)\n",
        "  H = Vt[-1].reshape(3,3) # take the last row of the Vt matrix\n",
        "  return H\n",
        "  \n",
        "  \n",
        "def displayplot(img,title):\n",
        "  \n",
        "  plt.figure(figsize=(15,15))\n",
        "  plt.title(title)\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJz6bnF_CgaL"
      },
      "source": [
        "def get_inliers(f1, f2, matches, H, RANSACthresh):\n",
        "\n",
        "  inlier_indices = []\n",
        "  for i in range(len(matches)):\n",
        "    queryInd = matches[i].queryIdx\n",
        "    trainInd = matches[i].trainIdx\n",
        "\n",
        "    #queryInd = matches[i][0]\n",
        "    #trainInd = matches[i][1]\n",
        "\n",
        "    queryPoint = np.array([f1[queryInd].pt[0],  f1[queryInd].pt[1], 1]).T \n",
        "    trans_query = H.dot(queryPoint) \n",
        "\n",
        "   \n",
        "    comp1 = [trans_query[0]/trans_query[2], trans_query[1]/trans_query[2]] # normalize with respect to z\n",
        "    comp2 = np.array(f2[trainInd].pt)[:2]\n",
        "    \n",
        "\n",
        "    if(np.linalg.norm(comp1-comp2) <= RANSACthresh): # check against threshold\n",
        "      inlier_indices.append(i)\n",
        "  return inlier_indices\n",
        "\n",
        "\n",
        "def RANSAC_alg(f1, f2, matches, nRANSAC, RANSACthresh):\n",
        "\n",
        "      \n",
        "    minMatches = 4\n",
        "    nBest = 0\n",
        "    best_inliers = []\n",
        "    H_estimate = np.eye(3,3)\n",
        "    global inlier_matchset\n",
        "    inlier_matchset=[]\n",
        "    for iteration in range(nRANSAC):\n",
        "      \n",
        "        #Choose a minimal set of feature matches.\n",
        "        matchSample = random.sample(matches, minMatches)\n",
        "        \n",
        "        #Estimate the Homography implied by these matches\n",
        "        im1_pts=np.empty((minMatches,2))\n",
        "        im2_pts=np.empty((minMatches,2))\n",
        "        for i in range(0,minMatches):\n",
        "          m = matchSample[i]\n",
        "          im1_pts[i] = f1[m.queryIdx].pt\n",
        "          im2_pts[i] = f2[m.trainIdx].pt\n",
        "          #im1_pts[i] = f1[m[0]].pt\n",
        "          #im2_pts[i] = f2[m[1]].pt             \n",
        "          \n",
        "        H_estimate=compute_Homography(im1_pts,im2_pts)\n",
        "        \n",
        "               \n",
        "        # Calculate the inliers for the H\n",
        "        inliers = get_inliers(f1, f2, matches, H_estimate, RANSACthresh)\n",
        "\n",
        "        # if the number of inliers is higher than previous iterations, update the best estimates\n",
        "        if len(inliers) > nBest:\n",
        "            nBest= len(inliers)\n",
        "            best_inliers = inliers\n",
        "\n",
        "    print(\"Number of best inliers\",len(best_inliers))\n",
        "    for i in range(len(best_inliers)):\n",
        "      inlier_matchset.append(matches[best_inliers[i]])\n",
        "    \n",
        "    # compute a homography given this set of matches\n",
        "    im1_pts=np.empty((len(best_inliers),2))\n",
        "    im2_pts=np.empty((len(best_inliers),2))\n",
        "    for i in range(0,len(best_inliers)):\n",
        "      m = inlier_matchset[i]\n",
        "      im1_pts[i] = f1[m.queryIdx].pt\n",
        "      im2_pts[i] = f2[m.trainIdx].pt\n",
        "      #im1_pts[i] = f1[m[0]].pt\n",
        "      #im2_pts[i] = f2[m[1]].pt\n",
        "\n",
        "    M=compute_Homography(im1_pts,im2_pts)\n",
        "    return M, best_inliers"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV-a3Gc2CgHC"
      },
      "source": [
        "tqdm = partial(tqdm, position=0, leave=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ZzIO2rDcxW"
      },
      "source": [
        "files_all=[]\n",
        "for file in os.listdir(\"/content/drive/MyDrive/rgb\"):\n",
        "    if file.endswith(\".JPG\"):\n",
        "      files_all.append(file)\n",
        "\n",
        "\n",
        "files_all.sort()\n",
        "folder_path = '/content/drive/MyDrive/rgb/'\n",
        "\n",
        "#centre_file = folder_path + files_all[50]\n",
        "left_files_path_rev = []\n",
        "right_files_path = []\n",
        "\n",
        "\n",
        "#Change this according to your dataset split\n",
        "\n",
        "for file in files_all[:41]:\n",
        "  left_files_path_rev.append(folder_path + file)\n",
        "\n",
        "left_files_path = left_files_path_rev[::-1]\n",
        "\n",
        "for file in files_all[40:80]:\n",
        "  right_files_path.append(folder_path + file)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqngRpI6UabS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e654c512-d4f1-4b1b-b8a4-2b4e021a234c"
      },
      "source": [
        "print(len(files_all))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERrE4NuoDcqr"
      },
      "source": [
        "from multiprocessing import Pool"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJYWbq9HDcaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa3a93a5-7946-4fc0-a9e8-c0f2d4646f47"
      },
      "source": [
        "import multiprocessing\n",
        "print(multiprocessing.cpu_count())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiG8CVOtHaP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a907bd-c143-4c55-98db-cade81b41877"
      },
      "source": [
        "gridsize = 8\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(gridsize,gridsize))\n",
        "\n",
        "images_left_bgr = []\n",
        "images_right_bgr = []\n",
        "\n",
        "images_left = []\n",
        "images_right = []\n",
        "\n",
        "for file in tqdm(left_files_path):\n",
        "  left_image_sat= cv2.imread(file)\n",
        "  #lab = cv2.cvtColor(left_image_sat, cv2.COLOR_BGR2LAB)\n",
        "  #lab[...,0] = clahe.apply(lab[...,0])\n",
        "  #left_image_sat = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "  left_img = cv2.resize(left_image_sat,None,fx=0.35, fy=0.35, interpolation = cv2.INTER_CUBIC )\n",
        "  images_left.append(cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY).astype('float32')/255.)\n",
        "  images_left_bgr.append(left_img)\n",
        "\n",
        "\n",
        "for file in tqdm(right_files_path):\n",
        "  right_image_sat= cv2.imread(file)\n",
        "  #lab = cv2.cvtColor(right_image_sat, cv2.COLOR_BGR2LAB)\n",
        "  #lab[...,0] = clahe.apply(lab[...,0])\n",
        "  #right_image_sat = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "  right_img = cv2.resize(right_image_sat,None,fx=0.35,fy=0.35, interpolation = cv2.INTER_CUBIC )\n",
        "  images_right.append(cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY).astype('float32')/255.)\n",
        "  images_right_bgr.append(right_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 24/41 [00:16<00:18,  1.08s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZZ5LCMiUjBR"
      },
      "source": [
        "Dataset = 'Industrial Dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcRM1Hn0HaKt"
      },
      "source": [
        "f=h5.File(f'drive/MyDrive/all_images_bgr_{Dataset}.h5','w')\n",
        "t0=time.time()\n",
        "f.create_dataset('data',data=images_left_bgr + images_right_bgr)\n",
        "f.close()\n",
        "print('HDF5  w/o comp.:',time.time()-t0,'[s] ... size',os.path.getsize(f'drive/MyDrive/all_images_bgr_{Dataset}.h5')/1.e6,'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuMrRmX4PUe1"
      },
      "source": [
        "del images_left_bgr,images_right_bgr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw1048ZtPUPW"
      },
      "source": [
        "from timeit import default_timer as timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEz_15CQRVZ4"
      },
      "source": [
        "time_all = []"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6qDnTfWRnoy"
      },
      "source": [
        "num_kps_sift = []\n",
        "num_kps_brisk = []\n",
        "num_kps_agast = []\n",
        "num_kps_kaze = []\n",
        "num_kps_akaze = []\n",
        "num_kps_orb = []\n",
        "num_kps_mser = []\n",
        "num_kps_daisy = []\n",
        "num_kps_surfsift = []\n",
        "num_kps_fast = []\n",
        "num_kps_freak = []\n",
        "num_kps_gftt = []\n",
        "num_kps_star = []\n",
        "num_kps_surf = []\n",
        "num_kps_rootsift = []\n",
        "num_kps_superpoint = []\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7DFuxxfT2Bq"
      },
      "source": [
        "images_left_bgr = []\n",
        "images_right_bgr = []"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8m3R7gIBOXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b768076b-c35c-4b17-bd01-93aa1bf2ee70"
      },
      "source": [
        "\n",
        "start = timer()\n",
        "\n",
        "sift = cv2.xfeatures2d.SIFT_create(contrastThreshold = 0.70, edgeThreshold = 30)\n",
        "keypoints_all_left_sift = []\n",
        "descriptors_all_left_sift = []\n",
        "points_all_left_sift=[]\n",
        "\n",
        "keypoints_all_right_sift = []\n",
        "descriptors_all_right_sift = []\n",
        "points_all_right_sift=[]\n",
        "\n",
        "\n",
        "for cnt in tqdm(range(len(left_files_path))):\n",
        "  f=h5.File(f'drive/MyDrive/all_images_bgr_{Dataset}.h5','r')\n",
        "  imgs = f['data'][cnt]\n",
        "  f.close()\n",
        "  kpt = sift.detect(imgs,None)\n",
        "  kpt,descrip =  sift.compute(imgs, kpt)\n",
        "  keypoints_all_left_sift.append(kpt)\n",
        "  descriptors_all_left_sift.append(descrip)\n",
        "  #points_all_left_sift.append(np.asarray([[p.pt[0], p.pt[1]] for p in kpt]))\n",
        "\n",
        "for cnt in tqdm(range(len(right_files_path))):\n",
        "  f=h5.File(f'drive/MyDrive/all_images_bgr_{Dataset}.h5','r')\n",
        "  imgs = f['data'][cnt+len(left_files_path)]\n",
        "  f.close()\n",
        "  kpt = sift.detect(imgs,None)\n",
        "  kpt,descrip =  sift.compute(imgs, kpt)\n",
        "  keypoints_all_right_sift.append(kpt)\n",
        "  descriptors_all_right_sift.append(descrip)\n",
        "  #points_all_right_sift.append(np.asarray([[p.pt[0], p.pt[1]] for p in kpt]))\n",
        "\n",
        "end = timer()\n",
        "\n",
        "time_all.append(end-start)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:25<00:00,  1.62it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:22<00:00,  1.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB_q6BV-BOTE"
      },
      "source": [
        "\n",
        "for j in tqdm(keypoints_all_left_sift + keypoints_all_right_sift[1:]):\n",
        "  num_kps_sift.append(len(j))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFAdEmiACcst"
      },
      "source": [
        "Total Matches,Robust Matches and Homography Computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1HvLX8HSWoQ"
      },
      "source": [
        "def compute_homography_fast(matched_pts1, matched_pts2,thresh=4):\n",
        "    #matched_pts1 = cv2.KeyPoint_convert(matched_kp1)\n",
        "    #matched_pts2 = cv2.KeyPoint_convert(matched_kp2)\n",
        "\n",
        "    # Estimate the homography between the matches using RANSAC\n",
        "    H, inliers = cv2.findHomography(matched_pts1,\n",
        "                                    matched_pts2,\n",
        "                                    cv2.RANSAC, ransacReprojThreshold =thresh, maxIters=3000)\n",
        "    inliers = inliers.flatten()\n",
        "    return H, inliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rQ1tDx0SWf9"
      },
      "source": [
        "def compute_homography_fast_other(matched_pts1, matched_pts2):\n",
        "    #matched_pts1 = cv2.KeyPoint_convert(matched_kp1)\n",
        "    #matched_pts2 = cv2.KeyPoint_convert(matched_kp2)\n",
        "\n",
        "    # Estimate the homography between the matches using RANSAC\n",
        "    H, inliers = cv2.findHomography(matched_pts1,\n",
        "                                    matched_pts2,\n",
        "                                    0)\n",
        "    inliers = inliers.flatten()\n",
        "    return H, inliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q8lSaVqTQIE"
      },
      "source": [
        "def get_Hmatrix(imgs,keypts,pts,descripts,ratio=0.75,thresh=4,use_lowe=True,disp=False,no_ransac=False,binary=False):\n",
        "  lff1 = descripts[0]\n",
        "  lff = descripts[1]\n",
        "\n",
        "  if use_lowe==False:\n",
        "    #FLANN_INDEX_KDTREE = 2\n",
        "    #index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    #search_params = dict(checks=50)\n",
        "    #flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    #flann = cv2.BFMatcher()\n",
        "    if binary==True:\n",
        "      bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    else:\n",
        "      bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "      lff1 = np.float32(descripts[0])\n",
        "      lff = np.float32(descripts[1])\n",
        "\n",
        "\n",
        "    #matches_lf1_lf = flann.knnMatch(lff1, lff, k=2)\n",
        "    matches_4 = bf.knnMatch(lff1, lff,k=2)\n",
        "    matches_lf1_lf = []\n",
        "\n",
        "\n",
        "    print(\"\\nNumber of matches\",len(matches_4))\n",
        "    '''\n",
        "    matches_4 = []\n",
        "    ratio = ratio\n",
        "    # loop over the raw matches\n",
        "    for m in matches_lf1_lf:\n",
        "      # ensure the distance is within a certain ratio of each\n",
        "      # other (i.e. Loweâ€™s ratio test)\n",
        "      #if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
        "          #matches_1.append((m[0].trainIdx, m[0].queryIdx))\n",
        "      matches_4.append(m[0])\n",
        "    '''\n",
        "    print(\"Number of matches After Lowe's Ratio\",len(matches_4))\n",
        "  else:\n",
        "    FLANN_INDEX_KDTREE = 2\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    if binary==True:\n",
        "      bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "      lff1 = np.float32(descripts[0])\n",
        "      lff = np.float32(descripts[1])\n",
        "    else:\n",
        "      bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
        "      lff1 = np.float32(descripts[0])\n",
        "      lff = np.float32(descripts[1])\n",
        "\n",
        "\n",
        "    matches_lf1_lf = flann.knnMatch(lff1, lff, k=2)\n",
        "    #matches_lf1_lf = bf.knnMatch(lff1, lff,k=2)\n",
        "\n",
        "\n",
        "    print(\"\\nNumber of matches\",len(matches_lf1_lf))\n",
        "    matches_4 = []\n",
        "    ratio = ratio\n",
        "    # loop over the raw matches\n",
        "    for m in matches_lf1_lf:\n",
        "      # ensure the distance is within a certain ratio of each\n",
        "      # other (i.e. Loweâ€™s ratio test)\n",
        "      if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
        "          #matches_1.append((m[0].trainIdx, m[0].queryIdx))\n",
        "        matches_4.append(m[0])\n",
        "  \n",
        "    print(\"Number of matches After Lowe's Ratio\",len(matches_4))\n",
        "\n",
        "\n",
        "  \n",
        "  matches_idx = np.array([m.queryIdx for m in matches_4])\n",
        "  imm1_pts = np.array([keypts[0][idx].pt for idx in matches_idx])\n",
        "  matches_idx = np.array([m.trainIdx for m in matches_4])\n",
        "  imm2_pts = np.array([keypts[1][idx].pt for idx in matches_idx])\n",
        "  '''\n",
        "  # Estimate homography 1\n",
        "  #Compute H1\n",
        "  # Estimate homography 1\n",
        "  #Compute H1\n",
        "  imm1_pts=np.empty((len(matches_4),2))\n",
        "  imm2_pts=np.empty((len(matches_4),2))\n",
        "  for i in range(0,len(matches_4)):\n",
        "    m = matches_4[i]\n",
        "    (a_x, a_y) = keypts[0][m.queryIdx].pt\n",
        "    (b_x, b_y) = keypts[1][m.trainIdx].pt\n",
        "    imm1_pts[i]=(a_x, a_y)\n",
        "    imm2_pts[i]=(b_x, b_y)    \n",
        "  H=compute_Homography(imm1_pts,imm2_pts) \n",
        "  #Robustly estimate Homography 1 using RANSAC\n",
        "  Hn, best_inliers=RANSAC_alg(keypts[0] ,keypts[1], matches_4,  nRANSAC=1000, RANSACthresh=6)\n",
        "  '''\n",
        "  \n",
        "  if no_ransac==True:\n",
        "    Hn,inliers = compute_homography_fast_other(imm1_pts,imm2_pts)\n",
        "  else:\n",
        "    Hn,inliers = compute_homography_fast(imm1_pts,imm2_pts,thresh)  \n",
        "\n",
        "  inlier_matchset = np.array(matches_4)[inliers.astype(bool)].tolist()\n",
        "  print(\"Number of Robust matches\",len(inlier_matchset))\n",
        "  print(\"\\n\")\n",
        "  \n",
        "  if len(inlier_matchset)<25:\n",
        "    matches_4 = []\n",
        "    ratio = 0.85\n",
        "    # loop over the raw matches\n",
        "    for m in matches_lf1_lf:\n",
        "      # ensure the distance is within a certain ratio of each\n",
        "      # other (i.e. Loweâ€™s ratio test)\n",
        "      if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
        "          #matches_1.append((m[0].trainIdx, m[0].queryIdx))\n",
        "          matches_4.append(m[0])\n",
        "    print(\"Number of matches After Lowe's Ratio New\",len(matches_4))\n",
        "  \n",
        "    matches_idx = np.array([m.queryIdx for m in matches_4])\n",
        "    imm1_pts = np.array([keypts[0][idx].pt for idx in matches_idx])\n",
        "    matches_idx = np.array([m.trainIdx for m in matches_4])\n",
        "    imm2_pts = np.array([keypts[1][idx].pt for idx in matches_idx])\n",
        "    Hn,inliers = compute_homography_fast(imm1_pts,imm2_pts)  \n",
        "    inlier_matchset = np.array(matches_4)[inliers.astype(bool)].tolist()\n",
        "    print(\"Number of Robust matches New\",len(inlier_matchset))\n",
        "    print(\"\\n\")    \n",
        "  \n",
        "  #H=compute_Homography(imm1_pts,imm2_pts) \n",
        "  #Robustly estimate Homography 1 using RANSAC\n",
        "  #Hn=RANSAC_alg(keypts[0] ,keypts[1], matches_4,  nRANSAC=1500, RANSACthresh=6)\n",
        "\n",
        "  #global inlier_matchset   \n",
        "  \n",
        "  if disp==True:\n",
        "    dispimg1=cv2.drawMatches(imgs[0], keypts[0], imgs[1], keypts[1], inlier_matchset, None,flags=2)\n",
        "    displayplot(dispimg1,'Robust Matching between Reference Image and Right Image ')\n",
        "  \n",
        "  \n",
        "  return Hn/Hn[2,2], len(matches_lf1_lf), len(inlier_matchset)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbSaUB-hTQDG"
      },
      "source": [
        "def get_Hmatrix_rfnet(imgs,pts,descripts,disp=True):\n",
        "\n",
        "  des1 = descripts[0]\n",
        "  des2 = descripts[1]\n",
        "\n",
        "  kp1 = pts[0]\n",
        "  kp2 = pts[1]\n",
        "\n",
        "\n",
        "  predict_label, nn_kp2 = nearest_neighbor_distance_ratio_match(des1, des2, kp2, 0.7)\n",
        "  idx = predict_label.nonzero().view(-1)\n",
        "  mkp1 = kp1.index_select(dim=0, index=idx.long())  # predict match keypoints in I1\n",
        "  mkp2 = nn_kp2.index_select(dim=0, index=idx.long())  # predict match keypoints in I2\n",
        "\n",
        "  #img1, img2 = reverse_img(img1), reverse_img(img2)\n",
        "  keypoints1 = list(map(to_cv2_kp, mkp1))\n",
        "  keypoints2 = list(map(to_cv2_kp, mkp2))\n",
        "  DMatch = list(map(to_cv2_dmatch, np.arange(0, len(keypoints1))))\n",
        "\n",
        "  imm1_pts=np.empty((len(DMatch),2))\n",
        "  imm2_pts=np.empty((len(DMatch),2))\n",
        "  for i in range(0,len(DMatch)):\n",
        "    m = DMatch[i]\n",
        "    (a_x, a_y) = keypoints1[m.queryIdx].pt\n",
        "    (b_x, b_y) = keypoints2[m.trainIdx].pt\n",
        "    imm1_pts[i]=(a_x, a_y)\n",
        "    imm2_pts[i]=(b_x, b_y)    \n",
        "  H=compute_Homography_fast(imm1_pts,imm2_pts) \n",
        "\n",
        "\n",
        "  if disp==True:\n",
        "    dispimg1 = cv2.drawMatches(imgs[0], keypoints1, imgs[1], keypoints2, DMatch, None)\n",
        "    displayplot(dispimg1,'Robust Matching between Reference Image and Right Image ')\n",
        "\n",
        "\n",
        "  return H/H[2,2]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzLUr-JVCpaE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "58187bd3-4a1a-48df-acd9-850919745308"
      },
      "source": [
        "\n",
        "H_left_sift = []\n",
        "H_right_sift = []\n",
        "\n",
        "num_matches_sift = []\n",
        "num_good_matches_sift = []\n",
        "\n",
        "for j in tqdm(range(len(left_files_path))):\n",
        "  if j==len(left_files_path)-1:\n",
        "    break\n",
        "\n",
        "  H_a,matches,gd_matches = get_Hmatrix(images_left_bgr[j:j+2][::-1],keypoints_all_left_sift[j:j+2][::-1],points_all_left_sift[j:j+2][::-1],descriptors_all_left_sift[j:j+2][::-1],1)\n",
        "  H_left_sift.append(H_a)\n",
        "  num_matches_sift.append(matches)\n",
        "  num_good_matches_sift.append(gd_matches)\n",
        "\n",
        "for j in tqdm(range(len(right_files_path))):\n",
        "  if j==len(right_files_path)-1:\n",
        "    break\n",
        "\n",
        "  H_a,matches,gd_matches = get_Hmatrix(images_right_bgr[j:j+2][::-1],keypoints_all_right_sift[j:j+2][::-1],points_all_right_sift[j:j+2][::-1],descriptors_all_right_sift[j:j+2][::-1],1)\n",
        "  H_right_sift.append(H_a)\n",
        "  num_matches_sift.append(matches)\n",
        "  num_good_matches_sift.append(gd_matches)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/41 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e7b1f87138b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mH_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgd_matches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Hmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_left_bgr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeypoints_all_left_sift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpoints_all_left_sift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdescriptors_all_left_sift\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mH_left_sift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mnum_matches_sift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-2cb51e37cdad>\u001b[0m in \u001b[0;36mget_Hmatrix\u001b[0;34m(imgs, keypts, pts, descripts, ratio, thresh, use_lowe, disp, no_ransac, binary)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmatches_lf1_lf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflann\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlff1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m#matches_lf1_lf = bf.knnMatch(lff1, lff,k=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trzf2eTGOOjd"
      },
      "source": [
        "Collect All Number Of KeyPoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HS4lRFrVkfT"
      },
      "source": [
        "len_files = len(left_files_path) + len(right_files_path[1:])\n",
        "num_detectors = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCck1fMMVkZ1"
      },
      "source": [
        "d = {'Dataset': [f'{Dataset}']*(num_detectors*len_files), 'Number of Keypoints': num_kps_sift, 'Detector/Descriptor':  ['SIFT']*len_files  }\n",
        "df_numkey_1 = pd.DataFrame(data=d)\n",
        "df_numkey_1['Number of Keypoints'] = df_numkey_1['Number of Keypoints']/(len_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAg-a2j-OVqA"
      },
      "source": [
        "#d = {'Dataset': ['University Campus']*(3*len_files), 'Number of Keypoints': num_kps_rootsift + num_kps_superpoint + num_kps_surf, 'Detector/Descriptor':['ROOTSIFT']*101 + ['SuperPoint']*101 + ['SURF']*101  }\n",
        "#df = pd.DataFrame(data=d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2PQojiuOVk0"
      },
      "source": [
        "#df_13 = pd.read_csv('drive/MyDrive/Num_Key_13.csv')\n",
        "#frames = [df_13, df]\n",
        "#df_16 = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3OVBuQNOVgo"
      },
      "source": [
        "#df_16.to_csv('drive/MyDrive/Num_Key_16.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRowM7PgOVZN"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "# Draw a nested barplot by species and sex\n",
        "g = sns.catplot(\n",
        "    data=df_numkey_1, kind=\"bar\",\n",
        "    x=\"Dataset\", y=\"Number of Keypoints\", hue=\"Detector/Descriptor\",\n",
        "    ci=\"sd\", palette=\"Spectral\", alpha=.9, height=6, aspect=2\n",
        ")\n",
        "g.despine(left=True)\n",
        "g.set_axis_labels(\"Dataset\", \"Number of Keypoints/Descriptors\")\n",
        "g.legend.set_title(\"Detector/Descriptor\")\n",
        "g.fig.suptitle(\"Number of Keypoints Detected for each Detector/Descriptor in Different Aerial Datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr91y79XOVR8"
      },
      "source": [
        "g.savefig(f'drive/MyDrive/Num_Kypoints_7_{Dataset}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDRlBi3XOd8f"
      },
      "source": [
        "df_numkey_1.to_csv(f'drive/MyDrive/Num_Kypoints_1_{Dataset}.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJa1lqz8oLgi"
      },
      "source": [
        "#print(len(num_matches_agast))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX8IMi-qOhTI"
      },
      "source": [
        "Total Number of Matches Detected for each Detector+Descriptor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmA0wyBIOd3l"
      },
      "source": [
        "#df_match_15['Number of Total Matches'] =  num_matches_agast + num_matches_akaze + num_matches_brisk + num_matches_daisy + num_matches_fast + num_matches_freak + num_matches_gftt + num_matches_kaze + num_matches_mser + num_matches_orb + num_matches_rootsift + num_matches_sift + num_matches_briefstar + num_matches_superpoint+ num_matches_surf+ num_matches_surfsift\n",
        "d = {'Dataset': [f'{Dataset}']*(num_detectors*(len_files-1)), 'Number of Total Matches': num_matches_sift , 'Detector/Descriptor':   ['SIFT']*(len_files-1)  }\n",
        "df_match_1 = pd.DataFrame(data=d)\n",
        "df_match_1['Number of Total Matches'] = df_match_1['Number of Total Matches']/(len_files-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUZ8fqlHOdzR"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "# Draw a nested barplot by species and sex\n",
        "g = sns.catplot(\n",
        "    data=df_match_7, kind=\"bar\",\n",
        "    x=\"Dataset\", y=\"Number of Total Matches\", hue=\"Detector/Descriptor\",\n",
        "    ci=\"sd\", palette=\"Spectral\", alpha=.9, height=10, aspect=0.5\n",
        ")\n",
        "g.despine(left=True)\n",
        "g.set_axis_labels(\"Dataset \", \"Total Number of Matches b/w Consecutive/Overlapping Images\")\n",
        "g.legend.set_title(\"Detector/Descriptor\")\n",
        "g.fig.suptitle(\"Total Number of Matches Detected for each Detector/Descriptor in Different Aerial Datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_WMsBjmOdu1"
      },
      "source": [
        "g.savefig(f'drive/MyDrive/Num_Matches_7_{Dataset}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv58xIv0Odqj"
      },
      "source": [
        "#df_match_16.to_csv('drive/MyDrive/Num_Matches_16.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPEmrVP9OrDR"
      },
      "source": [
        "Total Number of Good/Robust Matches (NN+Lowe+RANSAC) Detected for each Detector+Descriptor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx1DHmzTOt3P"
      },
      "source": [
        "df_match_1['Number of Good Matches'] =  num_good_matches_sift\n",
        "df_match_1['Number of Good Matches'] = df_match_1['Number of Good Matches']/(len_files-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmL182-COtzw"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "# Draw a nested barplot by species and sex\n",
        "g = sns.catplot(\n",
        "    data=df_match_7, kind=\"bar\",\n",
        "    x=\"Dataset\", y=\"Number of Good Matches\", hue=\"Detector/Descriptor\",\n",
        "    ci=\"sd\", palette=\"Spectral\", alpha=.9, height=10, aspect=0.5\n",
        ")\n",
        "g.despine(left=True)\n",
        "g.set_axis_labels(\"Dataset\", \"Number of Good Matches b/w Consecutive/Overlapping Images\")\n",
        "g.legend.set_title(\"Detector/Descriptor\")\n",
        "g.fig.suptitle(\"Number of Good Matches (Lowe + RANSAC) Detected for each Detector/Descriptor in Different Aerial Datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow42UY49OtvS"
      },
      "source": [
        "g.savefig('drive/MyDrive/Num_Good_Matches_7.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqbpFnFqOtro"
      },
      "source": [
        "#df_match_16.to_csv('drive/MyDrive/Num_Good_Matches_16.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgN-5TGVO1_A"
      },
      "source": [
        "Recall Rate for each Detector+Descriptor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_VaaFpO2oh"
      },
      "source": [
        "df_match_1['Recall Rate of Matches'] = df_match_1['Number of Good Matches']/df_match_1['Number of Total Matches']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRdc-FrzO5Na"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "g = sns.catplot(\n",
        "    data=df_match_7, kind=\"bar\",\n",
        "    x=\"Dataset\", y=\"Recall Rate of Matches\", hue=\"Detector/Descriptor\",\n",
        "    ci=\"sd\", palette=\"Spectral\", alpha=.9, height=10, aspect=0.5\n",
        ")\n",
        "g.despine(left=True)\n",
        "g.set_axis_labels(\"Dataset\", \"Precision of Matches\")\n",
        "g.legend.set_title(\"Detector/Descriptor\")\n",
        "g.fig.suptitle(\"Recall Rate of Matches Detected (Good/Total) for each Detector/Descriptor in Different Aerial Datasets (Higher the Better)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkDLeij5O5IP"
      },
      "source": [
        "g.savefig('drive/MyDrive/Recall_Rate_Matches_7.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QK0j7jsO-gP"
      },
      "source": [
        "1-Precision Rate for each Detector+Descriptor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbU_yfEfO5Cw"
      },
      "source": [
        "df_match_1['1 - Precision Rate of Matches'] = (df_match_1['Number of Total Matches'] - df_match_1['Number of Good Matches'])/df_match_1['Number of Total Matches']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQakh0q8O49P"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "# Draw a nested barplot by species and sex\n",
        "g = sns.catplot(\n",
        "    data=df_match_7, kind=\"bar\",\n",
        "    x=\"Dataset\", y=\"1 - Precision Rate of Matches\", hue=\"Detector/Descriptor\",\n",
        "    ci=\"sd\", palette=\"Spectral\", alpha=.9, height=10, aspect=0.5\n",
        ")\n",
        "g.despine(left=True)\n",
        "g.set_axis_labels(\"Dataset (120 Images)\", \"1 - Precision Rate of Matches\")\n",
        "g.legend.set_title(\"Detector/Descriptor\")\n",
        "g.fig.suptitle(\"1 - Precision rate of Matches Detected (False/Total Matches) for each Detector/Descriptor in Different Aerial Datasets (Lower the Better)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmcYnpiUO45J"
      },
      "source": [
        "g.savefig('drive/MyDrive/One_minus_Precision_Rate_Matches_7.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsiNPE0QPHQx"
      },
      "source": [
        "F-Score for each Detector+Descriptor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQdlNOnVPE77"
      },
      "source": [
        "df_match_1['F-Score'] = (2* (1 - df_match_1['1 - Precision Rate of Matches']) * df_match_1['Recall Rate of Matches'])/((1 - df_match_1['1 - Precision Rate of Matches']) + df_match_1['Recall Rate of Matches'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCtYcjcSPE4F"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "\n",
        "# Draw a nested barplot by species and sex\n",
        "g = sns.catplot(\n",
        "    data=df_match_7, kind=\"bar\",\n",
        "    x=\"Dataset\", y=\"F-Score\", hue=\"Detector/Descriptor\",\n",
        "    ci=\"sd\", palette=\"Spectral\", alpha=.9, height=10, aspect=0.5\n",
        ")\n",
        "g.despine(left=True)\n",
        "g.set_axis_labels(\"Dataset\", \"F-Score\")\n",
        "g.legend.set_title(\"Detector/Descriptor\")\n",
        "g.fig.suptitle(\"F-Score of Matches Detected (2*P*R/P+R) for each Detector/Descriptor in Different Aerial Datasets (Higher the Better)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibvFlM-QPE0j"
      },
      "source": [
        "g.savefig('drive/MyDrive/F_Score_Rate_Matches_7.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8uLq4m2PEvl"
      },
      "source": [
        "df_match_1.to_csv('drive/MyDrive/Industrial(contrastThreshold = 0.70, edgeThreshold = 30)(0.35).csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}